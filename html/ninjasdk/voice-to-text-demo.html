<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ooblex + NinjaSDK: Voice-to-Text Demo</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 16px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            max-width: 800px;
            width: 100%;
            padding: 40px;
        }

        h1 {
            color: #667eea;
            margin-bottom: 10px;
            font-size: 32px;
        }

        .subtitle {
            color: #666;
            margin-bottom: 30px;
            font-size: 14px;
        }

        .status-bar {
            background: #f5f5f5;
            border-radius: 8px;
            padding: 15px;
            margin-bottom: 20px;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .status-indicator {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            background: #ccc;
            animation: pulse 2s infinite;
        }

        .status-indicator.connected {
            background: #4ade80;
        }

        .status-indicator.recording {
            background: #f87171;
        }

        @keyframes pulse {
            0%, 100% {
                opacity: 1;
            }
            50% {
                opacity: 0.5;
            }
        }

        .controls {
            display: flex;
            gap: 15px;
            margin-bottom: 30px;
            flex-wrap: wrap;
        }

        button {
            flex: 1;
            min-width: 150px;
            padding: 15px 30px;
            border: none;
            border-radius: 8px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 8px;
        }

        button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
        }

        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
            transform: none;
        }

        .btn-start {
            background: #667eea;
            color: white;
        }

        .btn-stop {
            background: #f87171;
            color: white;
        }

        .btn-clear {
            background: #94a3b8;
            color: white;
        }

        .config-section {
            background: #f8fafc;
            border-radius: 8px;
            padding: 20px;
            margin-bottom: 30px;
        }

        .config-section h3 {
            margin-bottom: 15px;
            color: #334155;
            font-size: 16px;
        }

        .form-group {
            margin-bottom: 15px;
        }

        label {
            display: block;
            margin-bottom: 5px;
            color: #64748b;
            font-size: 14px;
            font-weight: 500;
        }

        input[type="text"] {
            width: 100%;
            padding: 10px;
            border: 2px solid #e2e8f0;
            border-radius: 6px;
            font-size: 14px;
            transition: border-color 0.3s ease;
        }

        input[type="text"]:focus {
            outline: none;
            border-color: #667eea;
        }

        .transcript-section {
            margin-top: 30px;
        }

        .transcript-section h3 {
            margin-bottom: 15px;
            color: #334155;
        }

        .transcript-box {
            background: #f8fafc;
            border: 2px solid #e2e8f0;
            border-radius: 8px;
            padding: 20px;
            min-height: 200px;
            max-height: 400px;
            overflow-y: auto;
            font-family: 'Courier New', monospace;
            font-size: 14px;
            line-height: 1.6;
        }

        .transcript-item {
            margin-bottom: 15px;
            padding: 10px;
            border-radius: 6px;
            animation: slideIn 0.3s ease;
        }

        @keyframes slideIn {
            from {
                opacity: 0;
                transform: translateY(-10px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .transcript-item.user {
            background: #dbeafe;
            border-left: 4px solid #3b82f6;
        }

        .transcript-item.assistant {
            background: #dcfce7;
            border-left: 4px solid #22c55e;
        }

        .transcript-item.system {
            background: #fef3c7;
            border-left: 4px solid #eab308;
        }

        .timestamp {
            color: #64748b;
            font-size: 11px;
            margin-bottom: 5px;
        }

        .confidence {
            display: inline-block;
            background: rgba(0, 0, 0, 0.1);
            padding: 2px 6px;
            border-radius: 4px;
            font-size: 11px;
            margin-left: 8px;
        }

        .text {
            color: #1e293b;
        }

        .stats {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 15px;
            margin-top: 30px;
        }

        .stat-card {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px;
            border-radius: 8px;
            text-align: center;
        }

        .stat-value {
            font-size: 28px;
            font-weight: 700;
            margin-bottom: 5px;
        }

        .stat-label {
            font-size: 12px;
            opacity: 0.9;
        }

        .audio-visualizer {
            background: #1e293b;
            border-radius: 8px;
            padding: 20px;
            margin: 20px 0;
            height: 100px;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 3px;
        }

        .visualizer-bar {
            width: 4px;
            background: #667eea;
            border-radius: 2px;
            transition: height 0.1s ease;
        }

        .info-box {
            background: #e0e7ff;
            border-left: 4px solid #667eea;
            padding: 15px;
            border-radius: 6px;
            margin-top: 20px;
        }

        .info-box h4 {
            color: #667eea;
            margin-bottom: 8px;
        }

        .info-box ul {
            margin-left: 20px;
            color: #475569;
            font-size: 14px;
        }

        .info-box li {
            margin-bottom: 5px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéôÔ∏è Ooblex + NinjaSDK Voice-to-Text</h1>
        <p class="subtitle">
            P2P WebRTC audio streaming ‚Üí Whisper STT ‚Üí Local LLM ‚Üí Real-time responses
        </p>

        <!-- Status Bar -->
        <div class="status-bar">
            <div class="status-indicator" id="statusIndicator"></div>
            <span id="statusText">Disconnected</span>
        </div>

        <!-- Configuration -->
        <div class="config-section">
            <h3>‚öôÔ∏è Configuration</h3>
            <div class="form-group">
                <label for="roomInput">Room Name</label>
                <input type="text" id="roomInput" placeholder="ooblex-audio" value="ooblex-audio">
            </div>
            <div class="form-group">
                <label for="passwordInput">Room Password (optional)</label>
                <input type="text" id="passwordInput" placeholder="">
            </div>
        </div>

        <!-- Controls -->
        <div class="controls">
            <button class="btn-start" id="startBtn">
                üé§ Start Speaking
            </button>
            <button class="btn-stop" id="stopBtn" disabled>
                ‚èπÔ∏è Stop
            </button>
            <button class="btn-clear" id="clearBtn">
                üóëÔ∏è Clear
            </button>
        </div>

        <!-- Audio Visualizer -->
        <div class="audio-visualizer" id="audioVisualizer">
            <!-- Bars will be generated by JavaScript -->
        </div>

        <!-- Transcript -->
        <div class="transcript-section">
            <h3>üìù Live Transcript</h3>
            <div class="transcript-box" id="transcriptBox">
                <div class="transcript-item system">
                    <div class="timestamp">System</div>
                    <div class="text">Click "Start Speaking" to begin. Speak naturally and watch as your voice is transcribed in real-time!</div>
                </div>
            </div>
        </div>

        <!-- Statistics -->
        <div class="stats">
            <div class="stat-card">
                <div class="stat-value" id="messagesCount">0</div>
                <div class="stat-label">Messages</div>
            </div>
            <div class="stat-card">
                <div class="stat-value" id="avgConfidence">0%</div>
                <div class="stat-label">Avg Confidence</div>
            </div>
            <div class="stat-card">
                <div class="stat-value" id="duration">0s</div>
                <div class="stat-label">Duration</div>
            </div>
        </div>

        <!-- Info Box -->
        <div class="info-box">
            <h4>How it works:</h4>
            <ul>
                <li>Your browser connects to NinjaSDK room via P2P WebRTC</li>
                <li>Audio streams directly to Ooblex audio ingestion service</li>
                <li>Whisper AI transcribes your speech in real-time</li>
                <li>Optional: Local LLM processes transcription and responds</li>
                <li>Responses come back via WebRTC data channels</li>
            </ul>
        </div>
    </div>

    <!-- NinjaSDK -->
    <script src="https://cdn.jsdelivr.net/npm/@vdoninja/sdk@latest/dist/vdo-ninja-sdk.min.js"></script>

    <script>
        class VoiceToTextApp {
            constructor() {
                this.sdk = null;
                this.audioStream = null;
                this.pc = null;
                this.dataChannel = null;
                this.isConnected = false;
                this.isRecording = false;
                this.startTime = null;
                this.stats = {
                    messages: 0,
                    totalConfidence: 0,
                };

                this.initUI();
                this.initVisualizer();
            }

            initUI() {
                this.startBtn = document.getElementById('startBtn');
                this.stopBtn = document.getElementById('stopBtn');
                this.clearBtn = document.getElementById('clearBtn');
                this.statusIndicator = document.getElementById('statusIndicator');
                this.statusText = document.getElementById('statusText');
                this.transcriptBox = document.getElementById('transcriptBox');
                this.roomInput = document.getElementById('roomInput');
                this.passwordInput = document.getElementById('passwordInput');

                this.startBtn.addEventListener('click', () => this.start());
                this.stopBtn.addEventListener('click', () => this.stop());
                this.clearBtn.addEventListener('click', () => this.clearTranscript());
            }

            initVisualizer() {
                const visualizer = document.getElementById('audioVisualizer');
                for (let i = 0; i < 32; i++) {
                    const bar = document.createElement('div');
                    bar.className = 'visualizer-bar';
                    bar.style.height = '10px';
                    visualizer.appendChild(bar);
                }
            }

            updateVisualizer(audioLevel) {
                const bars = document.querySelectorAll('.visualizer-bar');
                bars.forEach((bar, i) => {
                    const height = Math.random() * audioLevel * 80 + 10;
                    bar.style.height = `${height}px`;
                });
            }

            async start() {
                try {
                    this.updateStatus('connecting', 'Connecting...');
                    this.startBtn.disabled = true;

                    const room = this.roomInput.value || 'ooblex-audio';
                    const password = this.passwordInput.value || '';

                    // Initialize NinjaSDK
                    this.sdk = new VDONinjaSDK({
                        room: room,
                        password: password,
                        audio: true,
                        video: false,
                        label: 'Ooblex Voice Client',
                        debug: true,
                    });

                    // Connect to room
                    await this.sdk.connect();
                    await this.sdk.joinRoom();

                    // Get microphone access
                    this.audioStream = await navigator.mediaDevices.getUserMedia({
                        audio: {
                            echoCancellation: true,
                            noiseSuppression: true,
                            autoGainControl: true,
                            sampleRate: 48000,
                        },
                        video: false,
                    });

                    // Publish audio
                    await this.sdk.publish(this.audioStream);

                    // Setup data channel for receiving transcriptions
                    this.setupDataChannel();

                    // Start audio visualization
                    this.startAudioVisualization();

                    this.isConnected = true;
                    this.isRecording = true;
                    this.startTime = Date.now();

                    this.updateStatus('recording', 'Recording...');
                    this.startBtn.disabled = true;
                    this.stopBtn.disabled = false;

                    this.addMessage('system', 'Connected! Start speaking...');

                    // Update duration
                    this.durationInterval = setInterval(() => this.updateDuration(), 1000);

                } catch (error) {
                    console.error('Failed to start:', error);
                    alert('Failed to start: ' + error.message);
                    this.updateStatus('error', 'Error: ' + error.message);
                    this.startBtn.disabled = false;
                }
            }

            setupDataChannel() {
                // Listen for data channel from remote peer (audio ingestion service)
                this.sdk.on('dataReceived', (data, streamID) => {
                    console.log('Data received:', data);
                    this.handleDataChannelMessage(data);
                });
            }

            handleDataChannelMessage(data) {
                try {
                    const message = typeof data === 'string' ? JSON.parse(data) : data;

                    if (message.type === 'welcome') {
                        this.addMessage('system', message.message);
                    } else if (message.type === 'transcription') {
                        this.addMessage('user', message.text, message.confidence);
                        this.stats.messages++;
                        this.stats.totalConfidence += message.confidence || 0;
                        this.updateStats();
                    } else if (message.type === 'llm_response') {
                        this.addMessage('assistant', message.response);
                    }
                } catch (error) {
                    console.error('Failed to parse data channel message:', error);
                }
            }

            startAudioVisualization() {
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const analyser = audioContext.createAnalyser();
                const source = audioContext.createMediaStreamSource(this.audioStream);

                source.connect(analyser);
                analyser.fftSize = 64;

                const dataArray = new Uint8Array(analyser.frequencyBinCount);

                const visualize = () => {
                    if (!this.isRecording) return;

                    analyser.getByteFrequencyData(dataArray);
                    const average = dataArray.reduce((a, b) => a + b) / dataArray.length;
                    const normalized = average / 255;

                    this.updateVisualizer(normalized);

                    requestAnimationFrame(visualize);
                };

                visualize();
            }

            async stop() {
                try {
                    this.isRecording = false;
                    this.isConnected = false;

                    clearInterval(this.durationInterval);

                    // Stop audio tracks
                    if (this.audioStream) {
                        this.audioStream.getTracks().forEach(track => track.stop());
                        this.audioStream = null;
                    }

                    // Disconnect SDK
                    if (this.sdk) {
                        await this.sdk.disconnect();
                        this.sdk = null;
                    }

                    this.updateStatus('disconnected', 'Disconnected');
                    this.startBtn.disabled = false;
                    this.stopBtn.disabled = true;

                    this.addMessage('system', 'Stopped recording');

                } catch (error) {
                    console.error('Failed to stop:', error);
                }
            }

            updateStatus(state, text) {
                this.statusIndicator.className = 'status-indicator ' + state;
                this.statusText.textContent = text;
            }

            addMessage(type, text, confidence = null) {
                const item = document.createElement('div');
                item.className = `transcript-item ${type}`;

                const timestamp = document.createElement('div');
                timestamp.className = 'timestamp';
                timestamp.textContent = new Date().toLocaleTimeString();

                if (confidence !== null) {
                    const confidenceSpan = document.createElement('span');
                    confidenceSpan.className = 'confidence';
                    confidenceSpan.textContent = `${(confidence * 100).toFixed(0)}%`;
                    timestamp.appendChild(confidenceSpan);
                }

                const textDiv = document.createElement('div');
                textDiv.className = 'text';
                textDiv.textContent = text;

                item.appendChild(timestamp);
                item.appendChild(textDiv);

                this.transcriptBox.appendChild(item);
                this.transcriptBox.scrollTop = this.transcriptBox.scrollHeight;
            }

            clearTranscript() {
                this.transcriptBox.innerHTML = '';
                this.stats = { messages: 0, totalConfidence: 0 };
                this.updateStats();
                this.addMessage('system', 'Transcript cleared');
            }

            updateStats() {
                document.getElementById('messagesCount').textContent = this.stats.messages;

                const avgConfidence = this.stats.messages > 0
                    ? (this.stats.totalConfidence / this.stats.messages * 100).toFixed(0)
                    : 0;
                document.getElementById('avgConfidence').textContent = avgConfidence + '%';
            }

            updateDuration() {
                if (!this.startTime) return;
                const duration = Math.floor((Date.now() - this.startTime) / 1000);
                document.getElementById('duration').textContent = duration + 's';
            }
        }

        // Initialize app
        const app = new VoiceToTextApp();
    </script>
</body>
</html>
